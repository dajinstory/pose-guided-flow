name: pgflow_v4_test

gpus: [0] #,1,2,3] #[4,5,6,7]
seed: 310

n_epochs: 100
val_check_interval: 500 #0.5
log_every_n_steps: 100

experiment_root_path: /data/dajinhan/experiment

DATA:
  train:
    type: QuadrupletDataset
    root_path: /data/dajinhan/datasets/VoxCeleb/unzippedFaces_resized/64x64_png
    ldmk_root_path: /data/dajinhan/datasets/VoxCeleb/landmarks
    meta_path: /data/dajinhan/datasets/VoxCeleb/meta/png/train_frames_norm.csv
    abbreviation: false
    in_size: 64
    gt_size: 64

    use_hflip: true
    use_rot: false
    use_shuffle: true
    
    batch_size_per_gpu: 1
    num_workers: 1
    pin_memory: true
  
  valid:
    type: QuadrupletDataset
    root_path: /data/dajinhan/datasets/VoxCeleb/unzippedFaces_resized/64x64_png
    ldmk_root_path: /data/dajinhan/datasets/VoxCeleb/landmarks
    meta_path: /data/dajinhan/datasets/VoxCeleb/meta/png/valid_frames_norm_mini.csv
    # abbreviation: false #True
    abbreviation: false
    in_size: 64
    gt_size: 64

    use_hflip: false
    use_rot: false
    use_shuffle: false
    
    batch_size_per_gpu: 1
    num_workers: 1
    pin_memory: true
  
  test:
    type: QuadrupletDataset
    root_path: /data/dajinhan/datasets/VoxCeleb/unzippedFaces_resized/64x64_png
    ldmk_root_path: /data/dajinhan/datasets/VoxCeleb/landmarks
    meta_path: /data/dajinhan/datasets/VoxCeleb/meta/png/test_frames_norm_mini.csv
    # abbreviation: false #true
    abbreviation: false
    in_size: 64
    gt_size: 64

    use_hflip: false
    use_rot: false
    use_shuffle: false
    
    batch_size_per_gpu: 1
    num_workers: 1
    pin_memory: true


MODEL:
  type: "LitPGFlowV4"
  in_size: 64
  gt_size: 64
  n_bits: 8
  pretrained: 
    # ckpt_path: /data/dajinhan/experiment/pgflow_v4/checkpoint/last.ckpt

  flow_net:
    type: PGFlowV4
    args:
      inter_temp: 1.0
      final_temp: 1.0
      pretrained:
        # ckpt_path: /home/dajinhan/nas_dajinhan/experiments/pgflow_v3/l1_79.9979/pgflow.ckpt

  landmark_detector:
    type: FacialLandmarkDetector
    args:
      pretrained:
        ckpt_path: /home/dajinhan/nas_dajinhan/models/landmark_detector/checkpoint/mobilefacenet_model_best.pth.tar

  kd_module:
    type: InsightFaceModule
    args:
      pretrained: 
        ckpt_path: /home/dajinhan/nas_dajinhan/models/ArcFace/model_ir_se50.pth
      pretrained_headers:
        # ckpt_path: /home/dajinhan/nas_dajinhan/experiments/pgflow_v2/l1_79.9979/kd_headers.ckpt

  loss:
    nll:
      type: NLLLoss
      args:
        weight: 1.0
        n_bits: 8
    cvg:
      type: QuadrupletLoss
      args:
        weight: 5.0
        margin_pos: 0.0
        margin_neg: 0.3
    feature_guide:
      type: L1Loss
      args:
        weight: 10.0
    recon_self:
      type: L1Loss
      args:
        weight: 1.0 
    recon_cross:
      type: L1Loss
      args:
        weight: 1.0 
    perc_cross:
      type: PerceptualLoss
      args:
        weight_p: 1.0
        weight_s: 0.0
    id_cross:
      type: IDLoss
      args:
        weight: 1.0
        pretrained:
          ckpt_path: /home/dajinhan/nas_dajinhan/models/ArcFace/model_ir_se50.pth
    landmark:
      type: L1Loss
      args:
        weight: 10.0 
    facial5points:
      type: L1Loss
      args:
        weight: 10.0
        
  optim:
    type: Adam
    lr: !!float 1e-4
    weight_decay: 0
    betas: [0.9, 0.99]

  scheduler:
    type: CosineAnnealingLR
    T_max: 30
    eta_min: !!float 1e-7
  
